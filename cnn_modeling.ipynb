{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edb7d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01d4d03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:/dataset/programmers/train', 'D:/dataset/programmers/test')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = 'D:/dataset/programmers/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6832b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f2d630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224,224)\n",
    "generator = ImageDataGenerator(rotation_range=40,\n",
    "                          width_shift_range=0.2,\n",
    "                          height_shift_range=0.2,\n",
    "                          shear_range=0.2,\n",
    "                          zoom_range=0.2,\n",
    "                          horizontal_flip=True,\n",
    "                          vertical_flip=True,\n",
    "                          fill_mode = 'reflect',\n",
    "                          validation_split = 0.3,\n",
    "                          rescale=1/255.)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1/255.)\n",
    "# print(help(ImageDataGenerator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0594c039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1192 images belonging to 7 classes.\n",
      "Found 506 images belonging to 7 classes.\n",
      "Found 350 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = generator.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=IMG_SIZE,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True,\n",
    "            subset='training',)\n",
    "val_gen = generator.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=IMG_SIZE,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False,\n",
    "            subset='validation',)\n",
    "test_gen = test_generator.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=IMG_SIZE,\n",
    "#             class_mode='categorical',\n",
    "            shuffle=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86cb1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.DenseNet201(input_shape = (224,224,3), include_top = False)\n",
    "# print(help(tf.keras.applications.ResNet50(input_shape = IMG_SHAPE, include_top = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48645db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43402d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 7, 7, 1920)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input((224,224,3))\n",
    "x = resnet(inputs)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.35)(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb552601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=7, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=4)]\n",
    "\n",
    "model.compile(\n",
    "#     optimizer='adam',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6a9ef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "38/38 [==============================] - 28s 543ms/step - loss: 1.2404 - acc: 0.5369 - val_loss: 0.7975 - val_acc: 0.6937 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 11s 284ms/step - loss: 0.7148 - acc: 0.7424 - val_loss: 0.6289 - val_acc: 0.7747 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 11s 286ms/step - loss: 0.6012 - acc: 0.7894 - val_loss: 0.5732 - val_acc: 0.7984 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "38/38 [==============================] - 11s 287ms/step - loss: 0.4954 - acc: 0.8230 - val_loss: 0.5781 - val_acc: 0.8123 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "38/38 [==============================] - 11s 284ms/step - loss: 0.5050 - acc: 0.8205 - val_loss: 0.5620 - val_acc: 0.8043 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "38/38 [==============================] - 11s 286ms/step - loss: 0.3926 - acc: 0.8641 - val_loss: 0.5253 - val_acc: 0.8182 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "38/38 [==============================] - 11s 281ms/step - loss: 0.3987 - acc: 0.8641 - val_loss: 0.5700 - val_acc: 0.8083 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "38/38 [==============================] - 11s 283ms/step - loss: 0.4066 - acc: 0.8490 - val_loss: 0.5276 - val_acc: 0.8103 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "38/38 [==============================] - 11s 284ms/step - loss: 0.3650 - acc: 0.8607 - val_loss: 0.5038 - val_acc: 0.8103 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "38/38 [==============================] - 11s 286ms/step - loss: 0.3456 - acc: 0.8809 - val_loss: 0.5017 - val_acc: 0.8261 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "38/38 [==============================] - 11s 281ms/step - loss: 0.2691 - acc: 0.9052 - val_loss: 0.5641 - val_acc: 0.8123 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "38/38 [==============================] - 11s 284ms/step - loss: 0.2708 - acc: 0.9077 - val_loss: 0.5354 - val_acc: 0.8300 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "38/38 [==============================] - 10s 274ms/step - loss: 0.2680 - acc: 0.9094 - val_loss: 0.5447 - val_acc: 0.8202 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 0.2619 - acc: 0.9077 - val_loss: 0.5250 - val_acc: 0.8221 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.1977 - acc: 0.9362 - val_loss: 0.5488 - val_acc: 0.8360 - lr: 1.0000e-04\n",
      "Epoch 16/80\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 0.2092 - acc: 0.9304 - val_loss: 0.5840 - val_acc: 0.8281 - lr: 1.0000e-04\n",
      "Epoch 17/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 0.1929 - acc: 0.9346 - val_loss: 0.5373 - val_acc: 0.8360 - lr: 1.0000e-04\n",
      "Epoch 18/80\n",
      "38/38 [==============================] - 10s 258ms/step - loss: 0.1962 - acc: 0.9379 - val_loss: 0.5807 - val_acc: 0.8103 - lr: 1.0000e-04\n",
      "Epoch 19/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.1771 - acc: 0.9388 - val_loss: 0.4941 - val_acc: 0.8439 - lr: 1.0000e-05\n",
      "Epoch 20/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.1781 - acc: 0.9371 - val_loss: 0.5202 - val_acc: 0.8439 - lr: 1.0000e-05\n",
      "Epoch 21/80\n",
      "38/38 [==============================] - 10s 258ms/step - loss: 0.1888 - acc: 0.9388 - val_loss: 0.5184 - val_acc: 0.8320 - lr: 1.0000e-05\n",
      "Epoch 22/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.1475 - acc: 0.9530 - val_loss: 0.5485 - val_acc: 0.8360 - lr: 1.0000e-05\n",
      "Epoch 23/80\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 0.1416 - acc: 0.9555 - val_loss: 0.5977 - val_acc: 0.8123 - lr: 1.0000e-05\n",
      "Epoch 24/80\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 0.1541 - acc: 0.9497 - val_loss: 0.5466 - val_acc: 0.8360 - lr: 1.0000e-06\n",
      "Epoch 25/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 0.1780 - acc: 0.9279 - val_loss: 0.4991 - val_acc: 0.8419 - lr: 1.0000e-06\n",
      "Epoch 26/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.1606 - acc: 0.9430 - val_loss: 0.5629 - val_acc: 0.8221 - lr: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2474e3b45e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          validation_data = val_gen,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "128422ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 164ms/step\n",
      "(350, 7)\n",
      "[[2.8807041e-04 4.5052871e-06 9.9960905e-01 ... 4.2948872e-07\n",
      "  2.5535095e-07 9.7795993e-05]\n",
      " [4.7669730e-09 1.2208299e-09 7.6374596e-09 ... 3.9268633e-09\n",
      "  1.9015747e-09 2.3959208e-08]\n",
      " [2.5468612e-02 1.8907938e-02 3.0542307e-03 ... 1.3343780e-03\n",
      "  2.1876262e-04 4.1225296e-04]\n",
      " ...\n",
      " [8.5062544e-05 5.4363891e-06 1.4009899e-04 ... 7.7554942e-06\n",
      "  9.7386385e-07 2.8652963e-05]\n",
      " [4.8151100e-04 8.8206250e-03 4.8535258e-05 ... 6.3392438e-04\n",
      "  9.6715552e-01 1.4529819e-02]\n",
      " [1.7788501e-02 7.8034377e-01 1.1232614e-01 ... 8.3259024e-02\n",
      "  5.5934809e-04 5.2302713e-03]]\n",
      "[2 3 3 3 6 3 4 4 3 4 6 2 0 1 3 1 2 0 6 3 3 5 2 1 0 5 1 2 0 5 2 5 6 2 0 5 5\n",
      " 4 5 1 4 0 2 3 6 3 0 5 5 3 6 5 4 1 5 0 4 5 1 1 5 0 6 1 1 2 1 1 1 3 1 3 0 1\n",
      " 1 6 2 0 3 4 1 6 1 2 6 4 3 6 1 1 2 5 1 0 5 6 3 3 1 6 5 6 6 0 6 2 5 3 0 4 4\n",
      " 6 2 5 4 2 0 0 5 6 4 2 2 6 4 1 5 6 0 4 1 1 6 4 4 2 5 6 5 0 4 3 1 5 1 5 4 0\n",
      " 2 5 6 1 6 3 3 0 0 1 4 5 2 4 6 2 3 4 1 5 6 2 1 5 3 0 0 3 2 5 3 4 2 0 3 6 0\n",
      " 3 3 2 0 4 4 2 6 1 4 4 6 6 3 2 5 5 4 6 2 1 3 6 0 2 3 1 1 3 1 5 6 2 0 0 0 1\n",
      " 0 2 6 6 3 4 5 4 3 5 0 0 4 1 0 1 4 6 6 1 0 1 6 0 5 4 6 3 4 2 5 3 1 4 0 3 4\n",
      " 0 6 0 2 0 4 0 1 4 0 1 1 5 6 4 6 2 4 4 3 6 6 1 0 3 1 3 0 0 5 2 5 5 2 5 0 6\n",
      " 5 1 2 1 5 3 3 3 3 1 6 5 0 4 0 4 3 4 0 0 5 1 2 0 6 6 6 3 3 0 0 5 2 4 6 6 6\n",
      " 3 6 0 4 6 4 0 2 0 5 5 1 6 3 3 5 1]\n",
      "     Unnamed: 0  answer value\n",
      "0             0             2\n",
      "1             1             3\n",
      "2             2             3\n",
      "3             3             3\n",
      "4             4             6\n",
      "..          ...           ...\n",
      "345         345             6\n",
      "346         346             3\n",
      "347         347             3\n",
      "348         348             5\n",
      "349         349             1\n",
      "\n",
      "[350 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pred = model.predict(test_gen, verbose=1)\n",
    "print(pred.shape)\n",
    "print(pred)\n",
    "answer = np.array([y.argmax() for y in pred])\n",
    "print(answer)\n",
    "test_df = pd.read_csv(\"D:\\dataset\\programmers/test_answer_sample_.csv\")\n",
    "test_df.iloc[:,1] = answer\n",
    "print(test_df)\n",
    "test_df.to_csv('res_net_50v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0982cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "38/38 [==============================] - 11s 268ms/step - loss: 2.0525 - acc: 0.2081 - val_loss: 1.8680 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 10s 253ms/step - loss: 1.8496 - acc: 0.2458 - val_loss: 1.8361 - val_acc: 0.3043 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 10s 252ms/step - loss: 1.8065 - acc: 0.2945 - val_loss: 1.7982 - val_acc: 0.3142 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "38/38 [==============================] - 10s 250ms/step - loss: 1.7985 - acc: 0.2852 - val_loss: 1.7436 - val_acc: 0.3617 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "38/38 [==============================] - 10s 252ms/step - loss: 1.7759 - acc: 0.2919 - val_loss: 1.7478 - val_acc: 0.3676 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.7655 - acc: 0.3087 - val_loss: 1.7477 - val_acc: 0.3182 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.7841 - acc: 0.2961 - val_loss: 1.7326 - val_acc: 0.3419 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "38/38 [==============================] - 10s 250ms/step - loss: 1.7582 - acc: 0.2995 - val_loss: 1.8209 - val_acc: 0.2945 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.7778 - acc: 0.3054 - val_loss: 1.7740 - val_acc: 0.2984 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "38/38 [==============================] - 10s 250ms/step - loss: 1.7365 - acc: 0.3272 - val_loss: 1.7889 - val_acc: 0.2727 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.7424 - acc: 0.3255 - val_loss: 1.6919 - val_acc: 0.3794 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "38/38 [==============================] - 9s 249ms/step - loss: 1.7013 - acc: 0.3431 - val_loss: 1.7110 - val_acc: 0.3399 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "38/38 [==============================] - 9s 249ms/step - loss: 1.6768 - acc: 0.3607 - val_loss: 1.6962 - val_acc: 0.3557 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "38/38 [==============================] - 10s 250ms/step - loss: 1.6616 - acc: 0.3624 - val_loss: 1.7320 - val_acc: 0.3261 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "38/38 [==============================] - 10s 250ms/step - loss: 1.7027 - acc: 0.3414 - val_loss: 1.6833 - val_acc: 0.3696 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "38/38 [==============================] - 10s 252ms/step - loss: 1.6771 - acc: 0.3649 - val_loss: 1.7009 - val_acc: 0.3597 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.6808 - acc: 0.3557 - val_loss: 1.6837 - val_acc: 0.3854 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.6557 - acc: 0.3624 - val_loss: 1.6322 - val_acc: 0.4032 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "38/38 [==============================] - 10s 250ms/step - loss: 1.6194 - acc: 0.3935 - val_loss: 1.6551 - val_acc: 0.3834 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "38/38 [==============================] - 9s 249ms/step - loss: 1.6421 - acc: 0.3649 - val_loss: 1.6740 - val_acc: 0.3755 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.6470 - acc: 0.3666 - val_loss: 1.6253 - val_acc: 0.3913 - lr: 0.0010\n",
      "Epoch 22/80\n",
      "38/38 [==============================] - 10s 250ms/step - loss: 1.6084 - acc: 0.4102 - val_loss: 1.6369 - val_acc: 0.3755 - lr: 0.0010\n",
      "Epoch 23/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.5812 - acc: 0.3926 - val_loss: 1.6668 - val_acc: 0.3735 - lr: 0.0010\n",
      "Epoch 24/80\n",
      "38/38 [==============================] - 10s 252ms/step - loss: 1.6078 - acc: 0.3834 - val_loss: 1.6279 - val_acc: 0.4190 - lr: 0.0010\n",
      "Epoch 25/80\n",
      "38/38 [==============================] - 9s 249ms/step - loss: 1.5846 - acc: 0.3960 - val_loss: 1.6084 - val_acc: 0.3992 - lr: 0.0010\n",
      "Epoch 26/80\n",
      "38/38 [==============================] - 10s 250ms/step - loss: 1.5684 - acc: 0.3977 - val_loss: 1.6098 - val_acc: 0.4111 - lr: 0.0010\n",
      "Epoch 27/80\n",
      "38/38 [==============================] - 9s 248ms/step - loss: 1.5268 - acc: 0.4069 - val_loss: 1.6038 - val_acc: 0.3992 - lr: 0.0010\n",
      "Epoch 28/80\n",
      "38/38 [==============================] - 9s 248ms/step - loss: 1.5517 - acc: 0.4018 - val_loss: 1.6197 - val_acc: 0.4130 - lr: 0.0010\n",
      "Epoch 29/80\n",
      "38/38 [==============================] - 10s 250ms/step - loss: 1.5730 - acc: 0.3834 - val_loss: 1.6360 - val_acc: 0.3617 - lr: 0.0010\n",
      "Epoch 30/80\n",
      "38/38 [==============================] - 9s 250ms/step - loss: 1.5202 - acc: 0.4203 - val_loss: 1.5808 - val_acc: 0.3893 - lr: 0.0010\n",
      "Epoch 31/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.5383 - acc: 0.4119 - val_loss: 1.5851 - val_acc: 0.3972 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x249d4ef26d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=7, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "#     optimizer='adam',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_gen,\n",
    "          validation_data = val_gen,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff085616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "38/38 [==============================] - 11s 269ms/step - loss: 2.3361 - acc: 0.2265 - val_loss: 2.0558 - val_acc: 0.2490 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 1.8320 - acc: 0.2903 - val_loss: 1.9529 - val_acc: 0.2016 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 10s 275ms/step - loss: 1.9049 - acc: 0.2349 - val_loss: 1.7309 - val_acc: 0.3538 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "38/38 [==============================] - 10s 274ms/step - loss: 1.8332 - acc: 0.2768 - val_loss: 1.7531 - val_acc: 0.2628 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "38/38 [==============================] - 10s 278ms/step - loss: 1.7748 - acc: 0.3255 - val_loss: 1.7840 - val_acc: 0.2945 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "38/38 [==============================] - 10s 276ms/step - loss: 1.7800 - acc: 0.2861 - val_loss: 1.8014 - val_acc: 0.3004 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "38/38 [==============================] - 11s 282ms/step - loss: 1.7399 - acc: 0.3263 - val_loss: 1.7266 - val_acc: 0.3656 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "38/38 [==============================] - 10s 276ms/step - loss: 1.7079 - acc: 0.3456 - val_loss: 1.7199 - val_acc: 0.3498 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "38/38 [==============================] - 11s 279ms/step - loss: 1.7085 - acc: 0.3448 - val_loss: 1.6596 - val_acc: 0.3617 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "38/38 [==============================] - 11s 278ms/step - loss: 1.7270 - acc: 0.3523 - val_loss: 1.7180 - val_acc: 0.3320 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "38/38 [==============================] - 11s 278ms/step - loss: 1.7046 - acc: 0.3398 - val_loss: 1.6707 - val_acc: 0.3538 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "38/38 [==============================] - 11s 277ms/step - loss: 1.7085 - acc: 0.3540 - val_loss: 1.6905 - val_acc: 0.3794 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "38/38 [==============================] - 11s 278ms/step - loss: 1.7007 - acc: 0.3440 - val_loss: 1.5958 - val_acc: 0.4130 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "38/38 [==============================] - 11s 277ms/step - loss: 1.6501 - acc: 0.3683 - val_loss: 1.6497 - val_acc: 0.3794 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "38/38 [==============================] - 11s 284ms/step - loss: 1.6735 - acc: 0.3591 - val_loss: 1.6673 - val_acc: 0.3656 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "38/38 [==============================] - 10s 274ms/step - loss: 1.6368 - acc: 0.3851 - val_loss: 1.6170 - val_acc: 0.4071 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "38/38 [==============================] - 11s 279ms/step - loss: 1.6524 - acc: 0.3523 - val_loss: 1.6778 - val_acc: 0.3577 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "38/38 [==============================] - 11s 279ms/step - loss: 1.5905 - acc: 0.4010 - val_loss: 1.5641 - val_acc: 0.4150 - lr: 1.0000e-04\n",
      "Epoch 19/80\n",
      "38/38 [==============================] - 11s 279ms/step - loss: 1.5844 - acc: 0.4002 - val_loss: 1.5990 - val_acc: 0.4091 - lr: 1.0000e-04\n",
      "Epoch 20/80\n",
      "38/38 [==============================] - 11s 278ms/step - loss: 1.5711 - acc: 0.4002 - val_loss: 1.6314 - val_acc: 0.3696 - lr: 1.0000e-04\n",
      "Epoch 21/80\n",
      "38/38 [==============================] - 11s 279ms/step - loss: 1.5620 - acc: 0.4128 - val_loss: 1.6225 - val_acc: 0.3972 - lr: 1.0000e-04\n",
      "Epoch 22/80\n",
      "38/38 [==============================] - 11s 277ms/step - loss: 1.5516 - acc: 0.3993 - val_loss: 1.6163 - val_acc: 0.3794 - lr: 1.0000e-04\n",
      "Epoch 23/80\n",
      "38/38 [==============================] - 11s 279ms/step - loss: 1.5398 - acc: 0.3968 - val_loss: 1.6072 - val_acc: 0.3854 - lr: 1.0000e-05\n",
      "Epoch 24/80\n",
      "38/38 [==============================] - 11s 277ms/step - loss: 1.5510 - acc: 0.4186 - val_loss: 1.5840 - val_acc: 0.4150 - lr: 1.0000e-05\n",
      "Epoch 25/80\n",
      "38/38 [==============================] - 11s 280ms/step - loss: 1.5344 - acc: 0.4203 - val_loss: 1.6210 - val_acc: 0.3794 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x249f8b00b20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(help(tfa.activations))\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=tfa.activations.mish, input_shape=(224,224,3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.Dense(units=7, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "#     optimizer='adam',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_gen,\n",
    "          validation_data = val_gen,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d3f53d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4860\\1123391040.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmish\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m   1829\u001b[0m       return self._generator.uniform(\n\u001b[0;32m   1830\u001b[0m           shape=shape, minval=minval, maxval=maxval, dtype=dtype)\n\u001b[1;32m-> 1831\u001b[1;33m     return tf.random.uniform(\n\u001b[0m\u001b[0;32m   1832\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1833\u001b[0m         seed=self.make_legacy_seed())\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:Mul]"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(help(tfa.activations))\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=tfa.activations.mish, input_shape=(224,224,3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=tfa.activations.mish, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.Dense(units=7, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "#     optimizer='adam',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_gen,\n",
    "          validation_data = val_gen,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d8aafd0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 4.1024 - acc: 0.2047 - val_loss: 2.2590 - val_acc: 0.2213 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 2.2153 - acc: 0.2290 - val_loss: 2.1402 - val_acc: 0.2332 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 9s 249ms/step - loss: 2.0961 - acc: 0.2273 - val_loss: 2.0504 - val_acc: 0.2273 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 2.0319 - acc: 0.2492 - val_loss: 1.9746 - val_acc: 0.2826 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.9864 - acc: 0.2609 - val_loss: 1.9367 - val_acc: 0.3004 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "38/38 [==============================] - 10s 252ms/step - loss: 1.9365 - acc: 0.2869 - val_loss: 1.8856 - val_acc: 0.3043 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.9124 - acc: 0.3003 - val_loss: 1.8515 - val_acc: 0.3320 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.8890 - acc: 0.3221 - val_loss: 1.8952 - val_acc: 0.3142 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "38/38 [==============================] - 10s 252ms/step - loss: 1.8850 - acc: 0.3062 - val_loss: 1.8295 - val_acc: 0.3221 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 1.8539 - acc: 0.3171 - val_loss: 1.8218 - val_acc: 0.3617 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "38/38 [==============================] - 9s 249ms/step - loss: 1.8300 - acc: 0.3180 - val_loss: 1.8123 - val_acc: 0.3340 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "38/38 [==============================] - 10s 253ms/step - loss: 1.8329 - acc: 0.3213 - val_loss: 1.8386 - val_acc: 0.3577 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.8343 - acc: 0.3297 - val_loss: 1.8218 - val_acc: 0.3557 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "38/38 [==============================] - 10s 251ms/step - loss: 1.8094 - acc: 0.3582 - val_loss: 1.8117 - val_acc: 0.3597 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "38/38 [==============================] - 9s 249ms/step - loss: 1.8040 - acc: 0.3414 - val_loss: 1.8089 - val_acc: 0.3399 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "38/38 [==============================] - 9s 249ms/step - loss: 1.8116 - acc: 0.3381 - val_loss: 1.8301 - val_acc: 0.3142 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "38/38 [==============================] - 10s 250ms/step - loss: 1.7888 - acc: 0.3482 - val_loss: 1.7577 - val_acc: 0.3617 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a10a37700>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#he초기화는 별로....\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation='relu', input_shape=(224,224,3), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.Dense(units=7, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "#     optimizer='adam',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_gen,\n",
    "          validation_data = val_gen,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7011e207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_178 (Conv2D)         (None, 224, 224, 32)      320       \n",
      "                                                                 \n",
      " conv2d_179 (Conv2D)         (None, 224, 224, 32)      3104      \n",
      "                                                                 \n",
      " conv2d_180 (Conv2D)         (None, 224, 224, 32)      3104      \n",
      "                                                                 \n",
      " conv2d_181 (Conv2D)         (None, 224, 224, 32)      3104      \n",
      "                                                                 \n",
      " max_pooling2d_78 (MaxPoolin  (None, 112, 112, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_182 (Conv2D)         (None, 112, 112, 64)      18496     \n",
      "                                                                 \n",
      " conv2d_183 (Conv2D)         (None, 112, 112, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_79 (MaxPoolin  (None, 56, 56, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 200704)            0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 128)               25690240  \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,756,199\n",
      "Trainable params: 25,756,199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "38/38 [==============================] - 11s 264ms/step - loss: 2.3395 - acc: 0.2055 - val_loss: 2.0523 - val_acc: 0.2273 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 1.9583 - acc: 0.2659 - val_loss: 1.8859 - val_acc: 0.2589 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 1.9935 - acc: 0.2458 - val_loss: 1.9034 - val_acc: 0.3182 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "38/38 [==============================] - 10s 253ms/step - loss: 1.9326 - acc: 0.2794 - val_loss: 1.8933 - val_acc: 0.2925 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 1.9234 - acc: 0.2718 - val_loss: 1.8317 - val_acc: 0.3696 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 1.9075 - acc: 0.2760 - val_loss: 1.9209 - val_acc: 0.2767 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 1.9161 - acc: 0.2810 - val_loss: 1.8621 - val_acc: 0.3261 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 1.9230 - acc: 0.2802 - val_loss: 1.8687 - val_acc: 0.2727 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 1.8914 - acc: 0.2953 - val_loss: 1.8324 - val_acc: 0.2866 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 1.8322 - acc: 0.3129 - val_loss: 1.7785 - val_acc: 0.3597 - lr: 1.0000e-04\n",
      "Epoch 11/80\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 1.7864 - acc: 0.3456 - val_loss: 1.7402 - val_acc: 0.3953 - lr: 1.0000e-04\n",
      "Epoch 12/80\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 1.7675 - acc: 0.3372 - val_loss: 1.7150 - val_acc: 0.3834 - lr: 1.0000e-04\n",
      "Epoch 13/80\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 1.7491 - acc: 0.3565 - val_loss: 1.7068 - val_acc: 0.3775 - lr: 1.0000e-04\n",
      "Epoch 14/80\n",
      "38/38 [==============================] - 10s 252ms/step - loss: 1.7371 - acc: 0.3565 - val_loss: 1.6951 - val_acc: 0.3518 - lr: 1.0000e-04\n",
      "Epoch 15/80\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 1.7301 - acc: 0.3649 - val_loss: 1.6940 - val_acc: 0.3874 - lr: 1.0000e-04\n",
      "Epoch 16/80\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 1.7222 - acc: 0.3658 - val_loss: 1.6811 - val_acc: 0.3913 - lr: 1.0000e-04\n",
      "Epoch 17/80\n",
      "38/38 [==============================] - 10s 253ms/step - loss: 1.7165 - acc: 0.3742 - val_loss: 1.6689 - val_acc: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 18/80\n",
      "38/38 [==============================] - 10s 256ms/step - loss: 1.7158 - acc: 0.3523 - val_loss: 1.6679 - val_acc: 0.4051 - lr: 1.0000e-04\n",
      "Epoch 19/80\n",
      "38/38 [==============================] - 10s 253ms/step - loss: 1.7083 - acc: 0.3666 - val_loss: 1.6681 - val_acc: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 20/80\n",
      "38/38 [==============================] - 10s 253ms/step - loss: 1.7145 - acc: 0.3591 - val_loss: 1.6661 - val_acc: 0.4012 - lr: 1.0000e-04\n",
      "Epoch 21/80\n",
      "38/38 [==============================] - 10s 256ms/step - loss: 1.7012 - acc: 0.3658 - val_loss: 1.6553 - val_acc: 0.4269 - lr: 1.0000e-04\n",
      "Epoch 22/80\n",
      "38/38 [==============================] - 10s 252ms/step - loss: 1.7077 - acc: 0.3549 - val_loss: 1.6599 - val_acc: 0.4091 - lr: 1.0000e-04\n",
      "Epoch 23/80\n",
      "38/38 [==============================] - 10s 253ms/step - loss: 1.6944 - acc: 0.3624 - val_loss: 1.6625 - val_acc: 0.3913 - lr: 1.0000e-04\n",
      "Epoch 24/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 1.6910 - acc: 0.3691 - val_loss: 1.6581 - val_acc: 0.3854 - lr: 1.0000e-04\n",
      "Epoch 25/80\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 1.6864 - acc: 0.3842 - val_loss: 1.6398 - val_acc: 0.4209 - lr: 1.0000e-04\n",
      "Epoch 26/80\n",
      "38/38 [==============================] - 10s 256ms/step - loss: 1.6780 - acc: 0.3809 - val_loss: 1.6546 - val_acc: 0.4012 - lr: 1.0000e-04\n",
      "Epoch 27/80\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 1.6853 - acc: 0.3809 - val_loss: 1.6193 - val_acc: 0.4289 - lr: 1.0000e-04\n",
      "Epoch 28/80\n",
      "38/38 [==============================] - 10s 256ms/step - loss: 1.6544 - acc: 0.3977 - val_loss: 1.6640 - val_acc: 0.3775 - lr: 1.0000e-04\n",
      "Epoch 29/80\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 1.6695 - acc: 0.3666 - val_loss: 1.6355 - val_acc: 0.4269 - lr: 1.0000e-04\n",
      "Epoch 30/80\n",
      "38/38 [==============================] - 10s 258ms/step - loss: 1.6559 - acc: 0.3893 - val_loss: 1.6373 - val_acc: 0.4150 - lr: 1.0000e-04\n",
      "Epoch 31/80\n",
      "38/38 [==============================] - 10s 258ms/step - loss: 1.6599 - acc: 0.3918 - val_loss: 1.6698 - val_acc: 0.4051 - lr: 1.0000e-04\n",
      "Epoch 32/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 1.6261 - acc: 0.4178 - val_loss: 1.6531 - val_acc: 0.4051 - lr: 1.0000e-05\n",
      "Epoch 33/80\n",
      "38/38 [==============================] - 10s 256ms/step - loss: 1.6409 - acc: 0.4144 - val_loss: 1.6413 - val_acc: 0.4091 - lr: 1.0000e-05\n",
      "Epoch 34/80\n",
      "38/38 [==============================] - 10s 256ms/step - loss: 1.6189 - acc: 0.4237 - val_loss: 1.6294 - val_acc: 0.4111 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a075aca60>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,1), padding=\"same\", activation=tfa.activations.mish, input_shape=(224,224,3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(1,3), padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,1), padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(1,3), padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=tfa.activations.mish, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.Dense(units=7, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(\n",
    "#     optimizer='adam',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_gen,\n",
    "          validation_data = val_gen,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7803f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "38/38 [==============================] - 16s 299ms/step - loss: 2.0971 - acc: 0.2517 - val_loss: 1.9155 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 10s 258ms/step - loss: 1.8606 - acc: 0.2802 - val_loss: 1.9032 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 1.8362 - acc: 0.3070 - val_loss: 1.8942 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 1.8248 - acc: 0.2903 - val_loss: 1.8912 - val_acc: 0.1937 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 1.7883 - acc: 0.2894 - val_loss: 1.8835 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "38/38 [==============================] - 10s 264ms/step - loss: 1.7491 - acc: 0.3138 - val_loss: 1.8849 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.7301 - acc: 0.3297"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4860\\2249247594.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m               metrics=['acc'])\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m model.fit(train_gen,\n\u001b[0m\u001b[0;32m    130\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1252\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1253\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    947\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "import math\n",
    "\n",
    "se_ratio = 4\n",
    "expand_ratio = 6\n",
    "width_coefficient = 1.0\n",
    "depth_coefficient = 1.0\n",
    "default_resolution = 112\n",
    "input_channels = 3\n",
    "depth_divisor= 8 \n",
    "dropout_rate = 0.2\n",
    "drop_connect_rate = 0.2\n",
    "\n",
    "kernel_size = [3,3,5,3,5,5,3]\n",
    "num_repeat = [1,2,2,3,3,4,1]\n",
    "output_filters = [16,24,40,80,112,192,320]\n",
    "# strides = [1,2,1,2,1,2,1]\n",
    "strides = [1,2,2,2,1,2,1]\n",
    "MBConvBlock_1_True  =  [True,False,False,False,False,False,False]\n",
    "\n",
    "def round_repeats(repeats, depth_coefficient):\n",
    "    return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "def round_filters(filters, width_coefficient, depth_divisor):\n",
    "    filters *= width_coefficient\n",
    "    new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n",
    "    new_filters = max(depth_divisor, new_filters)\n",
    "    if new_filters < 0.9 * filters:\n",
    "        new_filters += depth_divisor\n",
    "    return int(new_filters)\n",
    "\n",
    "class DropConnect(layers.Layer):\n",
    "    def __init__(self, drop_connect_rate=0.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_connect_rate = drop_connect_rate\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        def _drop_connect():\n",
    "            keep_prob = 1.0 - self.drop_connect_rate\n",
    "\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            random_tensor = keep_prob\n",
    "            random_tensor += K.random_uniform([batch_size, 1, 1, 1], dtype=inputs.dtype)\n",
    "            binary_tensor = tf.floor(random_tensor)\n",
    "            output = tf.math.divide(inputs, keep_prob) * binary_tensor\n",
    "            return output\n",
    "\n",
    "        return K.in_train_phase(_drop_connect, inputs, training=training)\n",
    "    \n",
    "def SEBlock(filters,reduced_filters):\n",
    "    def _block(inputs):\n",
    "        x = layers.GlobalAveragePooling2D()(inputs)\n",
    "        x = layers.Reshape((1,1,x.shape[1]))(x)\n",
    "        x = layers.Conv2D(reduced_filters, 1, 1)(x)\n",
    "        x = tfa.activations.mish(x)\n",
    "        x = layers.Conv2D(filters, 1, 1)(x)\n",
    "        x = layers.Activation('sigmoid')(x)\n",
    "        x = layers.Multiply()([x, inputs])\n",
    "        return x\n",
    "    return _block\n",
    "\n",
    "def MBConvBlock(x,kernel_size, strides,drop_connect_rate,output_channels,MBConvBlock_1_True=False):\n",
    "    output_channels = round_filters(output_channels,width_coefficient,depth_divisor)\n",
    "    if MBConvBlock_1_True:\n",
    "        block = layers.DepthwiseConv2D(kernel_size, strides,padding='same', use_bias=False)(x)\n",
    "        block = layers.BatchNormalization()(block)\n",
    "        block = tfa.activations.mish(block)\n",
    "        block = SEBlock(x.shape[3],x.shape[3]/se_ratio)(block)\n",
    "        block = layers.Conv2D(output_channels, (1,1), padding='same', use_bias=False)(block)\n",
    "        block = layers.BatchNormalization()(block)\n",
    "        return block\n",
    "\n",
    "    channels = x.shape[3]\n",
    "    expand_channels = channels * expand_ratio\n",
    "    block = layers.Conv2D(expand_channels, (1,1), padding='same', use_bias=False)(x)\n",
    "    block = layers.BatchNormalization()(block)\n",
    "    block = tfa.activations.mish(block)\n",
    "    block = layers.DepthwiseConv2D(kernel_size, strides,padding='same', use_bias=False)(block)\n",
    "    block = layers.BatchNormalization()(block)\n",
    "    block = tfa.activations.mish(block)\n",
    "    block = SEBlock(expand_channels,channels/se_ratio)(block)\n",
    "    block = layers.Conv2D(output_channels, (1,1), padding='same', use_bias=False)(block)\n",
    "    block = layers.BatchNormalization()(block)\n",
    "    if x.shape[3] == output_channels:\n",
    "        block = DropConnect(drop_connect_rate)(block)\n",
    "        block = layers.Add()([block, x])\n",
    "    return block\n",
    "\n",
    "def Build_Network(num_classes, booster=False):\n",
    "    x_input = layers.Input(shape=(default_resolution,default_resolution,input_channels))    \n",
    "    x = layers.Conv2D(round_filters(32, width_coefficient, depth_divisor), (3,3), 2,padding='same', use_bias=False)(x_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = tfa.activations.mish(x)\n",
    "    num_blocks_total = sum(num_repeat)\n",
    "    block_num = 0\n",
    "    for i in range(len(kernel_size)):\n",
    "        round_num_repeat = round_repeats(num_repeat[i], depth_coefficient)\n",
    "        drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
    "        x = MBConvBlock(x,kernel_size[i],strides[i],drop_rate,output_filters[i],MBConvBlock_1_True = MBConvBlock_1_True[i])\n",
    "        block_num += 1\n",
    "        if round_num_repeat > 1:\n",
    "            for bidx in range(round_num_repeat - 1):\n",
    "                drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
    "                x = MBConvBlock(x,kernel_size[i],1,drop_rate,output_filters[i],MBConvBlock_1_True = MBConvBlock_1_True[i])\n",
    "                block_num += 1\n",
    "    x = layers.Conv2D(round_filters(1280, width_coefficient, depth_divisor), 1,padding='same',use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = tfa.activations.mish(x)\n",
    "    if booster==False:\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.Dense(num_classes,activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=x_input, outputs=x)\n",
    "    return model\n",
    "\n",
    "model = Build_Network(7)\n",
    "\n",
    "model.compile(\n",
    "#     optimizer='adam',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_gen,\n",
    "          validation_data = val_gen,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c5776fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_296 (Conv2D)            (None, 224, 224, 32  864         ['input_15[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 224, 224, 32  128        ['conv2d_296[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_80 (ReLU)                (None, 224, 224, 32  0           ['batch_normalization_130[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_54 (G  (None, 32)          0           ['re_lu_80[0][0]']               \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dense_125 (Dense)              (None, 2)            64          ['global_average_pooling2d_54[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_126 (Dense)              (None, 32)           64          ['dense_125[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_43 (Reshape)           (None, 1, 1, 32)     0           ['dense_126[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_42 (Multiply)         (None, 224, 224, 32  0           ['re_lu_80[0][0]',               \n",
      "                                )                                 'reshape_43[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_106 (MaxPooling2  (None, 112, 112, 32  0          ['multiply_42[0][0]']            \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_49 (Depthwise  (None, 112, 112, 32  288        ['max_pooling2d_106[0][0]']      \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 112, 112, 32  128        ['depthwise_conv2d_49[0][0]']    \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_81 (ReLU)                (None, 112, 112, 32  0           ['batch_normalization_131[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_297 (Conv2D)            (None, 112, 112, 64  2048        ['re_lu_81[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, 112, 112, 64  256        ['conv2d_297[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_82 (ReLU)                (None, 112, 112, 64  0           ['batch_normalization_132[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_55 (G  (None, 64)          0           ['re_lu_82[0][0]']               \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dense_127 (Dense)              (None, 4)            256         ['global_average_pooling2d_55[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_128 (Dense)              (None, 64)           256         ['dense_127[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_44 (Reshape)           (None, 1, 1, 64)     0           ['dense_128[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_43 (Multiply)         (None, 112, 112, 64  0           ['re_lu_82[0][0]',               \n",
      "                                )                                 'reshape_44[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_107 (MaxPooling2  (None, 56, 56, 64)  0           ['multiply_43[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_50 (Depthwise  (None, 56, 56, 64)  576         ['max_pooling2d_107[0][0]']      \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, 56, 56, 64)  256         ['depthwise_conv2d_50[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_83 (ReLU)                (None, 56, 56, 64)   0           ['batch_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_298 (Conv2D)            (None, 56, 56, 128)  8192        ['re_lu_83[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 56, 56, 128)  512        ['conv2d_298[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_84 (ReLU)                (None, 56, 56, 128)  0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling2d_56 (G  (None, 128)         0           ['re_lu_84[0][0]']               \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dense_129 (Dense)              (None, 8)            1024        ['global_average_pooling2d_56[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_130 (Dense)              (None, 128)          1024        ['dense_129[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_45 (Reshape)           (None, 1, 1, 128)    0           ['dense_130[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_44 (Multiply)         (None, 56, 56, 128)  0           ['re_lu_84[0][0]',               \n",
      "                                                                  'reshape_45[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_108 (MaxPooling2  (None, 28, 28, 128)  0          ['multiply_44[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_51 (Depthwise  (None, 28, 28, 128)  1152       ['max_pooling2d_108[0][0]']      \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 28, 28, 128)  512        ['depthwise_conv2d_51[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_85 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_299 (Conv2D)            (None, 28, 28, 256)  32768       ['re_lu_85[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, 28, 28, 256)  1024       ['conv2d_299[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_86 (ReLU)                (None, 28, 28, 256)  0           ['batch_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling2d_57 (G  (None, 256)         0           ['re_lu_86[0][0]']               \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dense_131 (Dense)              (None, 16)           4096        ['global_average_pooling2d_57[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_132 (Dense)              (None, 256)          4096        ['dense_131[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_46 (Reshape)           (None, 1, 1, 256)    0           ['dense_132[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_45 (Multiply)         (None, 28, 28, 256)  0           ['re_lu_86[0][0]',               \n",
      "                                                                  'reshape_46[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_109 (MaxPooling2  (None, 14, 14, 256)  0          ['multiply_45[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_52 (Depthwise  (None, 14, 14, 256)  2304       ['max_pooling2d_109[0][0]']      \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, 14, 14, 256)  1024       ['depthwise_conv2d_52[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_87 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_300 (Conv2D)            (None, 14, 14, 512)  131072      ['re_lu_87[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, 14, 14, 512)  2048       ['conv2d_300[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_88 (ReLU)                (None, 14, 14, 512)  0           ['batch_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling2d_58 (G  (None, 512)         0           ['re_lu_88[0][0]']               \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dense_133 (Dense)              (None, 32)           16384       ['global_average_pooling2d_58[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_134 (Dense)              (None, 512)          16384       ['dense_133[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_47 (Reshape)           (None, 1, 1, 512)    0           ['dense_134[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_46 (Multiply)         (None, 14, 14, 512)  0           ['re_lu_88[0][0]',               \n",
      "                                                                  'reshape_47[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_59 (G  (None, 512)         0           ['multiply_46[0][0]']            \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 512)          0           ['global_average_pooling2d_59[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_135 (Dense)              (None, 7)            3591        ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 232,391\n",
      "Trainable params: 229,447\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 11s 269ms/step - loss: 1.8064 - acc: 0.3012 - val_loss: 1.9126 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 1.6863 - acc: 0.3616 - val_loss: 1.8950 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 1.6509 - acc: 0.3473 - val_loss: 1.9041 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "13/38 [=========>....................] - ETA: 4s - loss: 1.5281 - acc: 0.4362"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4860\\1281073597.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m               metrics=['acc'])\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m model.fit(train_gen,\n\u001b[0m\u001b[0;32m     70\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    548\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \"\"\"\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def SEBlock(input_feature, ratio=16):\n",
    "    \"\"\"Squeeze and Excitation Block.\"\"\"\n",
    "    channel_axis = -1\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "    \n",
    "    se_shape = (1, 1, channel)\n",
    "    se = GlobalAveragePooling2D()(input_feature)\n",
    "    se = Dense(channel // ratio, activation='relu', use_bias=False)(se)\n",
    "    se = Dense(channel, activation='sigmoid', use_bias=False)(se)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    return Multiply()([input_feature, se])\n",
    "\n",
    "def conv_and_se_block(x, filters):\n",
    "    \"\"\"A helper function to apply Convolution + SE Block.\"\"\"\n",
    "    x = Conv2D(filters, (3, 3), padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SEBlock(x)\n",
    "    return x\n",
    "\n",
    "def depthwise_sep_conv_and_se_block(x, filters):\n",
    "    \"\"\"A helper function to apply Depthwise Separable Conv + SE Block.\"\"\"\n",
    "    x = DepthwiseConv2D((3, 3), padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters, (1, 1), padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SEBlock(x)\n",
    "    return x\n",
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = conv_and_se_block(inputs, 32)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = depthwise_sep_conv_and_se_block(x, 64)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = depthwise_sep_conv_and_se_block(x, 128)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Additional depth for larger input size\n",
    "    x = depthwise_sep_conv_and_se_block(x, 256)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = depthwise_sep_conv_and_se_block(x, 512)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# 모델 생성 (예: CIFAR-10의 입력 크기와 클래스 수 사용)\n",
    "model = make_model((224, 224, 3), 7)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "#     optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_gen,\n",
    "          validation_data = val_gen,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "82b27cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_385 (Conv2D)         (None, 224, 224, 32)      320       \n",
      "                                                                 \n",
      " conv2d_386 (Conv2D)         (None, 224, 224, 32)      3104      \n",
      "                                                                 \n",
      " conv2d_387 (Conv2D)         (None, 224, 224, 32)      3104      \n",
      "                                                                 \n",
      " conv2d_388 (Conv2D)         (None, 224, 224, 32)      3104      \n",
      "                                                                 \n",
      " max_pooling2d_149 (MaxPooli  (None, 112, 112, 32)     0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_389 (Conv2D)         (None, 112, 112, 64)      18496     \n",
      "                                                                 \n",
      " conv2d_390 (Conv2D)         (None, 112, 112, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_150 (MaxPooli  (None, 56, 56, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_59 (Flatten)        (None, 200704)            0         \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 128)               25690240  \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,756,199\n",
      "Trainable params: 25,756,199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "38/38 [==============================] - 11s 273ms/step - loss: 0.5274 - acc: 0.2106 - val_loss: 0.3744 - val_acc: 0.2411 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 10s 262ms/step - loss: 0.3780 - acc: 0.2466 - val_loss: 0.3593 - val_acc: 0.3004 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 10s 267ms/step - loss: 0.3598 - acc: 0.2802 - val_loss: 0.3749 - val_acc: 0.3083 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "38/38 [==============================] - 10s 270ms/step - loss: 0.3635 - acc: 0.2651 - val_loss: 0.3376 - val_acc: 0.2905 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "38/38 [==============================] - 10s 265ms/step - loss: 0.3558 - acc: 0.2592 - val_loss: 0.3422 - val_acc: 0.3261 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "38/38 [==============================] - 10s 272ms/step - loss: 0.3602 - acc: 0.2391 - val_loss: 0.3361 - val_acc: 0.3300 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "38/38 [==============================] - 10s 267ms/step - loss: 0.3489 - acc: 0.2852 - val_loss: 0.3328 - val_acc: 0.3379 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "38/38 [==============================] - 10s 264ms/step - loss: 0.3615 - acc: 0.2827 - val_loss: 0.3336 - val_acc: 0.3123 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "38/38 [==============================] - 10s 264ms/step - loss: 0.3617 - acc: 0.2718 - val_loss: 0.3572 - val_acc: 0.3083 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "38/38 [==============================] - 10s 266ms/step - loss: 0.3622 - acc: 0.2701 - val_loss: 0.3479 - val_acc: 0.3083 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.3523 - acc: 0.3003 - val_loss: 0.3670 - val_acc: 0.2372 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.3476 - acc: 0.3029 - val_loss: 0.3187 - val_acc: 0.3794 - lr: 1.0000e-04\n",
      "Epoch 13/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.3238 - acc: 0.3238 - val_loss: 0.3039 - val_acc: 0.3538 - lr: 1.0000e-04\n",
      "Epoch 14/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.3167 - acc: 0.3188 - val_loss: 0.2970 - val_acc: 0.3794 - lr: 1.0000e-04\n",
      "Epoch 15/80\n",
      "38/38 [==============================] - 10s 258ms/step - loss: 0.3116 - acc: 0.3163 - val_loss: 0.2976 - val_acc: 0.3656 - lr: 1.0000e-04\n",
      "Epoch 16/80\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.3113 - acc: 0.3414 - val_loss: 0.2951 - val_acc: 0.3874 - lr: 1.0000e-04\n",
      "Epoch 17/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.3108 - acc: 0.3440 - val_loss: 0.2916 - val_acc: 0.3755 - lr: 1.0000e-04\n",
      "Epoch 18/80\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.3063 - acc: 0.3339 - val_loss: 0.2901 - val_acc: 0.4091 - lr: 1.0000e-04\n",
      "Epoch 19/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.3085 - acc: 0.3448 - val_loss: 0.2897 - val_acc: 0.3953 - lr: 1.0000e-04\n",
      "Epoch 20/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.3070 - acc: 0.3314 - val_loss: 0.2876 - val_acc: 0.4032 - lr: 1.0000e-04\n",
      "Epoch 21/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.3044 - acc: 0.3356 - val_loss: 0.2875 - val_acc: 0.4111 - lr: 1.0000e-04\n",
      "Epoch 22/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.3024 - acc: 0.3465 - val_loss: 0.2920 - val_acc: 0.3735 - lr: 1.0000e-04\n",
      "Epoch 23/80\n",
      "38/38 [==============================] - 10s 258ms/step - loss: 0.3021 - acc: 0.3591 - val_loss: 0.2914 - val_acc: 0.3755 - lr: 1.0000e-04\n",
      "Epoch 24/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.3077 - acc: 0.3398 - val_loss: 0.2879 - val_acc: 0.3755 - lr: 1.0000e-04\n",
      "Epoch 25/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.3025 - acc: 0.3599 - val_loss: 0.2849 - val_acc: 0.4209 - lr: 1.0000e-04\n",
      "Epoch 26/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.3017 - acc: 0.3582 - val_loss: 0.2892 - val_acc: 0.4130 - lr: 1.0000e-04\n",
      "Epoch 27/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 0.3013 - acc: 0.3607 - val_loss: 0.2908 - val_acc: 0.4170 - lr: 1.0000e-04\n",
      "Epoch 28/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.3021 - acc: 0.3683 - val_loss: 0.2947 - val_acc: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 29/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.3008 - acc: 0.3565 - val_loss: 0.2895 - val_acc: 0.3972 - lr: 1.0000e-04\n",
      "Epoch 30/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.2998 - acc: 0.3641 - val_loss: 0.2875 - val_acc: 0.3893 - lr: 1.0000e-05\n",
      "Epoch 31/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.2937 - acc: 0.3867 - val_loss: 0.2850 - val_acc: 0.4012 - lr: 1.0000e-05\n",
      "Epoch 32/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.2923 - acc: 0.3775 - val_loss: 0.2839 - val_acc: 0.4328 - lr: 1.0000e-05\n",
      "Epoch 33/80\n",
      "38/38 [==============================] - 10s 263ms/step - loss: 0.2941 - acc: 0.3742 - val_loss: 0.2833 - val_acc: 0.4229 - lr: 1.0000e-05\n",
      "Epoch 34/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.2913 - acc: 0.3809 - val_loss: 0.2850 - val_acc: 0.4032 - lr: 1.0000e-05\n",
      "Epoch 35/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.2897 - acc: 0.3834 - val_loss: 0.2803 - val_acc: 0.4269 - lr: 1.0000e-05\n",
      "Epoch 36/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.2923 - acc: 0.3641 - val_loss: 0.2808 - val_acc: 0.4209 - lr: 1.0000e-05\n",
      "Epoch 37/80\n",
      "38/38 [==============================] - 10s 263ms/step - loss: 0.2910 - acc: 0.3851 - val_loss: 0.2803 - val_acc: 0.4170 - lr: 1.0000e-05\n",
      "Epoch 38/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.2889 - acc: 0.3842 - val_loss: 0.2821 - val_acc: 0.4051 - lr: 1.0000e-05\n",
      "Epoch 39/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.2910 - acc: 0.3700 - val_loss: 0.2823 - val_acc: 0.4071 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a35a3e610>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "# def SEBlock(input_feature, ratio=16):\n",
    "#     channel_axis = -1\n",
    "#     channel = input_feature.shape[channel_axis]\n",
    "    \n",
    "#     se_shape = (1, 1, channel)\n",
    "#     se = layers.GlobalAveragePooling2D()(input_feature)\n",
    "#     se = layers.Reshape(se_shape)(se)\n",
    "#     se = layers.Dense(channel // ratio, activation='relu', use_bias=False)(se)\n",
    "#     se = layers.Dense(channel, activation='sigmoid', use_bias=False)(se)\n",
    "#     se = layers.Reshape(se_shape)(se)\n",
    "#     return layers.Multiply()([input_feature, se])\n",
    "\n",
    "# def conv_and_se_block(x, filters):\n",
    "#     x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "#     x = tfa.activations.mish(x)\n",
    "#     x = layers.DepthwiseConv2D(3, padding=\"same\")(x)\n",
    "#     x = tfa.activations.mish(x)\n",
    "#     x = layers.Conv2D(filters, 1, padding=\"same\")(x)\n",
    "#     x = tfa.activations.mish(x)\n",
    "#     x = SEBlock(x)\n",
    "#     return x\n",
    "\n",
    "# def make_model(input_shape=(224, 224, 3), num_classes=7):\n",
    "#     inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "#     x = conv_and_se_block(inputs, 32)\n",
    "#     x = layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "#     x = conv_and_se_block(x, 64)\n",
    "#     x = layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "# #     x = conv_and_se_block(x, 128)\n",
    "# #     x = layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "\n",
    "#     x = layers.Flatten()(x)\n",
    "#     x = layers.Dense(128, activation=tfa.activations.mish, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "#     x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#     model = models.Model(inputs=inputs, outputs=x)\n",
    "#     model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "#     return model\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,1), padding=\"same\", activation=tfa.activations.mish, input_shape=(224,224,3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(1,3), padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,1), padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(1,3), padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=tfa.activations.mish))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=tfa.activations.mish, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.Dense(units=7, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# 모델 생성\n",
    "# model = make_model()\n",
    "\n",
    "# focal_loss = tfa.losses.SigmoidFocalCrossEntropy()\n",
    "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Focal Loss for multi-class or categorical classification.\n",
    "    This loss function generalizes the idea of Focal Loss to multi-class classification.\n",
    "    \"\"\"\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Focal loss calculation.\n",
    "        \"\"\"\n",
    "        # Clip the prediction value to prevent NaN's and Inf's\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        # Calculate Cross Entropy\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "\n",
    "        # Calculate Focal Loss\n",
    "        loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n",
    "\n",
    "        # Sum the losses in mini_batch\n",
    "        return tf.reduce_sum(loss, axis=1)\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "\n",
    "\n",
    "model.compile(\n",
    "#     optimizer='adam',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "              loss=categorical_focal_loss(gamma=2., alpha=0.25),\n",
    "#               loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_gen,\n",
    "          validation_data = val_gen,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bd1e889e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "38/38 [==============================] - 13s 277ms/step - loss: 0.3657 - acc: 0.2097 - val_loss: 0.3417 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 0.3480 - acc: 0.2257 - val_loss: 0.3455 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 10s 258ms/step - loss: 0.3471 - acc: 0.2089 - val_loss: 0.3464 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.3472 - acc: 0.2206 - val_loss: 0.3421 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "38/38 [==============================] - 10s 258ms/step - loss: 0.3439 - acc: 0.2232 - val_loss: 0.3448 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "38/38 [==============================] - 10s 263ms/step - loss: 0.3433 - acc: 0.2315 - val_loss: 0.3404 - val_acc: 0.2352 - lr: 1.0000e-04\n",
      "Epoch 7/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.3419 - acc: 0.2315 - val_loss: 0.3399 - val_acc: 0.2352 - lr: 1.0000e-04\n",
      "Epoch 8/80\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.3408 - acc: 0.2299 - val_loss: 0.3400 - val_acc: 0.2352 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a36085880>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False,\n",
    "                                                  weights='imagenet',\n",
    "                                                  input_shape=(224, 224, 3))\n",
    "\n",
    "# 기본 모델의 층을 고정 (가중치를 업데이트하지 않음)\n",
    "base_model.trainable = False\n",
    "\n",
    "# 모델 구축\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),  # 특징 맵을 하나의 특징 벡터로 변환\n",
    "    layers.Dense(1024, activation='relu'),  # 새로운 분류 층\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(7, activation='softmax')  # 가정: 10개의 클래스가 있다\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "#     optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "              loss=categorical_focal_loss(gamma=2., alpha=0.25),\n",
    "#               loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_gen,\n",
    "          validation_data = val_gen,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "36874468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1192 images belonging to 7 classes.\n",
      "Found 506 images belonging to 7 classes.\n",
      "Found 350 images belonging to 1 classes.\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " global_average_pooling2d_10  (None, 1280)             0         \n",
      " 5 (GlobalAveragePooling2D)                                      \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 512)               655872    \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,709,034\n",
      "Trainable params: 659,463\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "38/38 [==============================] - 12s 274ms/step - loss: 0.3540 - acc: 0.2072 - val_loss: 0.3417 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 10s 256ms/step - loss: 0.3450 - acc: 0.2232 - val_loss: 0.3432 - val_acc: 0.1937 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 0.3441 - acc: 0.2215 - val_loss: 0.3425 - val_acc: 0.1937 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.3418 - acc: 0.2383 - val_loss: 0.3401 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.3424 - acc: 0.2030 - val_loss: 0.3403 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 0.3420 - acc: 0.2341 - val_loss: 0.3402 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 0.3408 - acc: 0.2307 - val_loss: 0.3401 - val_acc: 0.2352 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "38/38 [==============================] - 10s 258ms/step - loss: 0.3416 - acc: 0.2341 - val_loss: 0.3408 - val_acc: 0.2352 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a4356c520>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = 'D:/dataset/programmers/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "train_dir, test_dir\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "generator = ImageDataGenerator(rotation_range=40,\n",
    "                          width_shift_range=0.2,\n",
    "                          height_shift_range=0.2,\n",
    "#                           shear_range=0.2,\n",
    "#                           zoom_range=0.2,\n",
    "                          horizontal_flip=True,\n",
    "#                           vertical_flip=True,\n",
    "                          fill_mode = 'reflect',\n",
    "                          validation_split = 0.3,\n",
    "                          rescale=1/255.)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1/255.)\n",
    "# print(help(ImageDataGenerator))\n",
    "\n",
    "train_gen = generator.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=IMG_SIZE,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True,\n",
    "            subset='training',)\n",
    "val_gen = generator.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=IMG_SIZE,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False,\n",
    "            subset='validation',)\n",
    "test_gen = test_generator.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=IMG_SIZE,\n",
    "#             class_mode='categorical',\n",
    "            shuffle=False,)\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False,\n",
    "                                                  weights='imagenet',\n",
    "                                                  input_shape=(224, 224, 3))\n",
    "\n",
    "# 기본 모델의 층을 고정 (가중치를 업데이트하지 않음)\n",
    "base_model.trainable = False\n",
    "\n",
    "# 모델 구축\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),  # 특징 맵을 하나의 특징 벡터로 변환\n",
    "    layers.Dense(512, activation='relu'),  # 새로운 분류 층\n",
    "#     layers.Dropout(0.2),\n",
    "    layers.Dense(7, activation='softmax')  # 가정: 10개의 클래스가 있다\n",
    "])\n",
    "model.summary()\n",
    "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Focal Loss for multi-class or categorical classification.\n",
    "    This loss function generalizes the idea of Focal Loss to multi-class classification.\n",
    "    \"\"\"\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Focal loss calculation.\n",
    "        \"\"\"\n",
    "        # Clip the prediction value to prevent NaN's and Inf's\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        # Calculate Cross Entropy\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "\n",
    "        # Calculate Focal Loss\n",
    "        loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n",
    "\n",
    "        # Sum the losses in mini_batch\n",
    "        return tf.reduce_sum(loss, axis=1)\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=7, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=4)]\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "#     optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "              loss=categorical_focal_loss(gamma=2., alpha=0.25),\n",
    "#               loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_gen,\n",
    "          validation_data = val_gen,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b63f81ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 files belonging to 10 classes.\n",
      "Using 40000 files for training.\n",
      "Found 50000 files belonging to 10 classes.\n",
      "Using 10000 files for validation.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Epoch 1/80\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "1250/1250 [==============================] - 104s 81ms/step - loss: 2.2930 - acc: 0.1253 - val_loss: 2.2479 - val_acc: 0.1521 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "1250/1250 [==============================] - 101s 81ms/step - loss: 2.2365 - acc: 0.1498 - val_loss: 2.2318 - val_acc: 0.1526 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "1250/1250 [==============================] - 102s 81ms/step - loss: 2.2122 - acc: 0.1633 - val_loss: 2.1934 - val_acc: 0.1817 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "1250/1250 [==============================] - 101s 81ms/step - loss: 2.1877 - acc: 0.1760 - val_loss: 2.1657 - val_acc: 0.1910 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "1250/1250 [==============================] - 101s 81ms/step - loss: 2.1608 - acc: 0.1889 - val_loss: 2.1283 - val_acc: 0.2168 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "1250/1250 [==============================] - 102s 81ms/step - loss: 2.1322 - acc: 0.2042 - val_loss: 2.0903 - val_acc: 0.2288 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "1250/1250 [==============================] - 102s 81ms/step - loss: 2.1118 - acc: 0.2115 - val_loss: 2.0627 - val_acc: 0.2373 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "1250/1250 [==============================] - 101s 81ms/step - loss: 2.0910 - acc: 0.2227 - val_loss: 2.0715 - val_acc: 0.2228 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "1250/1250 [==============================] - 101s 81ms/step - loss: 2.0770 - acc: 0.2285 - val_loss: 2.0185 - val_acc: 0.2516 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "1250/1250 [==============================] - 102s 81ms/step - loss: 2.0672 - acc: 0.2342 - val_loss: 2.0011 - val_acc: 0.2678 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "1250/1250 [==============================] - 101s 81ms/step - loss: 2.0470 - acc: 0.2411 - val_loss: 1.9823 - val_acc: 0.2740 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "1250/1250 [==============================] - 101s 81ms/step - loss: 2.0375 - acc: 0.2442 - val_loss: 1.9748 - val_acc: 0.2677 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "1250/1250 [==============================] - 102s 81ms/step - loss: 2.0287 - acc: 0.2494 - val_loss: 1.9819 - val_acc: 0.2781 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "1250/1250 [==============================] - 102s 81ms/step - loss: 2.0166 - acc: 0.2519 - val_loss: 1.9646 - val_acc: 0.2661 - lr: 0.0010\n",
      "Epoch 15/80\n",
      " 991/1250 [======================>.......] - ETA: 18s - loss: 2.0081 - acc: 0.2602"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17300\\3716667458.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m               metrics=['acc'])\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m model.fit(train_ds,\n\u001b[0m\u001b[0;32m     98\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "base_dir = 'D:/dataset/cifar10/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "train_dir, test_dir\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(224, 224),\n",
    "  batch_size=32)\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(224, 224),\n",
    "  batch_size=32)\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_dir,\n",
    "  seed=123,\n",
    "  image_size=(224, 224),\n",
    "  batch_size=32)\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.Rescaling(1. / 255),\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "base_model = tf.keras.applications.ResNet50(include_top=False,\n",
    "                                                  weights='imagenet',\n",
    "                                                  input_shape=(224, 224, 3))\n",
    "\n",
    "# 기본 모델의 층을 고정 (가중치를 업데이트하지 않음)\n",
    "base_model.trainable = False\n",
    "\n",
    "# 모델 구축\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),  # 특징 맵을 하나의 특징 벡터로 변환\n",
    "    layers.Dense(512, activation='relu'),  # 새로운 분류 층\n",
    "#     layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')  # 가정: 10개의 클래스가 있다\n",
    "])\n",
    "# model.summary()\n",
    "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Focal Loss for multi-class or categorical classification.\n",
    "    This loss function generalizes the idea of Focal Loss to multi-class classification.\n",
    "    \"\"\"\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Focal loss calculation.\n",
    "        \"\"\"\n",
    "        # Clip the prediction value to prevent NaN's and Inf's\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        # Calculate Cross Entropy\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "\n",
    "        # Calculate Focal Loss\n",
    "        loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n",
    "\n",
    "        # Sum the losses in mini_batch\n",
    "        return tf.reduce_sum(loss, axis=1)\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=7, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=4)]\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "#     optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     optimizer=tfa.optimizers.AdamW(0.001),\n",
    "#               loss=categorical_focal_loss(gamma=2., alpha=0.25),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data = val_ds,\n",
    "          epochs=80,\n",
    "          callbacks=callback\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aede49f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package keras.api._v2.keras.applications in keras.api._v2.keras:\n",
      "\n",
      "NAME\n",
      "    keras.api._v2.keras.applications - Keras Applications are premade architectures with pre-trained weights.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    convnext (package)\n",
      "    densenet (package)\n",
      "    efficientnet (package)\n",
      "    efficientnet_v2 (package)\n",
      "    imagenet_utils (package)\n",
      "    inception_resnet_v2 (package)\n",
      "    inception_v3 (package)\n",
      "    mobilenet (package)\n",
      "    mobilenet_v2 (package)\n",
      "    mobilenet_v3 (package)\n",
      "    nasnet (package)\n",
      "    regnet (package)\n",
      "    resnet (package)\n",
      "    resnet50 (package)\n",
      "    resnet_rs (package)\n",
      "    resnet_v2 (package)\n",
      "    vgg16 (package)\n",
      "    vgg19 (package)\n",
      "    xception (package)\n",
      "\n",
      "FILE\n",
      "    c:\\users\\jiwoon\\anaconda3\\lib\\site-packages\\keras\\api\\_v2\\keras\\applications\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.applications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbcf96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
